{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env MODEL =  /opt/intel/openvino/deployment_tools/open_model_zoo/tools/downloader/intel/person-detection-retail-0013/FP32/person-detection-retail-0013.xml\n",
    "%env USE_SAFETY_MODEL = ../resources/worker-safety-mobilenet/FP32/worker_safety_mobilenet.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    " Copyright (c) 2018 Intel Corporation.\n",
    "\n",
    " Permission is hereby granted, free of charge, to any person obtaining\n",
    " a copy of this software and associated documentation files (the\n",
    " \"Software\"), to deal in the Software without restriction, including\n",
    " without limitation the rights to use, copy, modify, merge, publish,\n",
    " distribute, sublicense, and/or sell copies of the Software, and to\n",
    " permit persons to whom the Software is furnished to do so, subject to\n",
    " the following conditions:\n",
    "\n",
    " The above copyright notice and this permission notice shall be\n",
    " included in all copies or substantial portions of the Software.\n",
    "\n",
    " THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n",
    " EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n",
    " MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n",
    " NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n",
    " LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n",
    " OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n",
    " WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "from inference import Network\n",
    "\n",
    "# Global vars\n",
    "cpu_extension = ''\n",
    "conf_modelLayers = ''\n",
    "conf_modelWeights = ''\n",
    "targetDevice = \"CPU\"\n",
    "conf_batchSize = 1\n",
    "conf_modelPersonLabel = 1\n",
    "conf_inferConfidenceThreshold = 0.7\n",
    "conf_inFrameViolationsThreshold = 19\n",
    "conf_inFramePeopleThreshold = 5\n",
    "padding = 30\n",
    "viol_wk = 0\n",
    "acceptedDevices = ['CPU', 'GPU', 'MYRIAD', 'HETERO:FPGA,CPU', 'HDDL']\n",
    "videos = []\n",
    "name_of_videos = []\n",
    "CONFIG_FILE = '../resources/config.json'\n",
    "\n",
    "class Video:\n",
    "    def __init__(self, idx, path):\n",
    "        if path.isnumeric():\n",
    "            self.video = cv2.VideoCapture(int(path))\n",
    "            self.name = \"Cam \" + str(idx)\n",
    "        else:\n",
    "            if os.path.exists(path):\n",
    "                self.video = cv2.VideoCapture(path)\n",
    "                self.name = \"Video \" + str(idx)\n",
    "            else:\n",
    "                print(\"Either wrong input path or empty line is found. Please check the conf.json file\")\n",
    "                exit(21)\n",
    "        if not self.video.isOpened():\n",
    "            print(\"Couldn't open video: \" + path)\n",
    "            sys.exit(20)\n",
    "        self.height = int(self.video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        self.width = int(self.video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "        self.currentViolationCount = 0\n",
    "        self.currentViolationCountConfidence = 0\n",
    "        self.prevViolationCount = 0\n",
    "        self.totalViolations = 0\n",
    "        self.totalPeopleCount = 0\n",
    "        self.currentPeopleCount = 0\n",
    "        self.currentPeopleCountConfidence = 0\n",
    "        self.prevPeopleCount = 0\n",
    "        self.currentTotalPeopleCount = 0\n",
    "\n",
    "        cv2.namedWindow(self.name, cv2.WINDOW_NORMAL)\n",
    "        self.frame_start_time = datetime.datetime.now()\n",
    "\n",
    "\n",
    "def env_parser():\n",
    "    \"\"\"\n",
    "    Parses the inputs.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    global use_safety_model, conf_modelLayers, conf_modelWeights, targetDevice, cpu_extension, videos,\\\n",
    "                conf_safety_modelWeights, conf_safety_modelLayers, is_async_mode\n",
    "    if 'MODEL' in os.environ:\n",
    "        conf_modelLayers = os.environ['MODEL']\n",
    "        conf_modelWeights = os.path.splitext(conf_modelLayers)[0] + \".bin\"\n",
    "    else:\n",
    "        print(\"Please provide path for the .xml file.\")\n",
    "        sys.exit(0)\n",
    "    if 'DEVICE' in os.environ:\n",
    "        targetDevice = os.environ['DEVICE']\n",
    "        if 'MULTI' not in targetDevice and targetDevice not in acceptedDevices:\n",
    "            print(\"Unsupported device: \" + targetDevice)\n",
    "            sys.exit(2)\n",
    "        elif 'MULTI' in targetDevice:\n",
    "            target_devices = targetDevice.split(':')[1].split(',')\n",
    "            for multi_device in target_devices:\n",
    "                if multi_device not in acceptedDevices:\n",
    "                    print(\"Unsupported device: \" + targetDevice)\n",
    "                    sys.exit(2)\n",
    "    if 'CPU_EXTENSION' in os.environ:\n",
    "        cpu_extension = os.environ['CPU_EXTENSION']\n",
    "    if 'USE_SAFETY_MODEL' in os.environ:\n",
    "        conf_safety_modelLayers = os.environ['USE_SAFETY_MODEL']\n",
    "        conf_safety_modelWeights = os.path.splitext(conf_safety_modelLayers)[0] + \".bin\"\n",
    "        use_safety_model = True\n",
    "    else:\n",
    "        use_safety_model = False\n",
    "    if 'FLAG' in os.environ:\n",
    "        if os.environ['FLAG'] == 'async':\n",
    "            is_async_mode = True\n",
    "            print('Application running in Async mode')\n",
    "        else:\n",
    "            is_async_mode = False\n",
    "            print('Application running in Sync mode')\n",
    "    else:\n",
    "        is_async_mode = True\n",
    "        print('Application running in Async mode')\n",
    "    assert os.path.isfile(CONFIG_FILE), \"{} file doesn't exist\".format(CONFIG_FILE)\n",
    "    config = json.loads(open(CONFIG_FILE).read())\n",
    "    for idx, item in enumerate(config['inputs']):\n",
    "        vid = Video(idx, item['video'])\n",
    "        name_of_videos.append([idx, item['video']])\n",
    "        videos.append([idx, vid])\n",
    "\n",
    "\n",
    "\n",
    "def detect_safety_hat(img):\n",
    "    \"\"\"\n",
    "    Detection of the hat of the person.\n",
    "    :param img: Current frame\n",
    "    :return: Boolean value of the detected hat\n",
    "    \"\"\"\n",
    "    lowH = 15\n",
    "    lowS = 65\n",
    "    lowV = 75\n",
    "\n",
    "    highH = 30\n",
    "    highS = 255\n",
    "    highV = 255\n",
    "\n",
    "    crop = 0\n",
    "    height = 15\n",
    "    perc = 8\n",
    "\n",
    "    hsv = np.zeros(1)\n",
    "\n",
    "    try:\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    except cv2.error as e:\n",
    "        print(\"%d %d %d\" % (img.shape))\n",
    "        print(\"%d %d %d\" % (img.shape))\n",
    "        print(e)\n",
    "\n",
    "    threshold_img = cv2.inRange(hsv, (lowH, lowS, lowV), (highH, highS, highV))\n",
    "\n",
    "    x = 0\n",
    "    y = int(threshold_img.shape[0] * crop / 100)\n",
    "    w = int(threshold_img.shape[1])\n",
    "    h = int(threshold_img.shape[0] * height / 100)\n",
    "    img_cropped = threshold_img[y: y + h, x: x + w]\n",
    "\n",
    "    if cv2.countNonZero(threshold_img) < img_cropped.size * perc / 100:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def detect_safety_jacket(img):\n",
    "    \"\"\"\n",
    "    Detection of the safety jacket of the person.\n",
    "    :param img: Current frame\n",
    "    :return: Boolean value of the detected jacket\n",
    "    \"\"\"\n",
    "    lowH = 0\n",
    "    lowS = 150\n",
    "    lowV = 42\n",
    "\n",
    "    highH = 11\n",
    "    highS = 255\n",
    "    highV = 255\n",
    "\n",
    "    crop = 15\n",
    "    height = 40\n",
    "    perc = 23\n",
    "\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    threshold_img = cv2.inRange(hsv, (lowH, lowS, lowV), (highH, highS, highV))\n",
    "\n",
    "    x = 0\n",
    "    y = int(threshold_img.shape[0] * crop / 100)\n",
    "    w = int(threshold_img.shape[1])\n",
    "    h = int(threshold_img.shape[0] * height / 100)\n",
    "    img_cropped = threshold_img[y: y + h, x: x + w]\n",
    "\n",
    "    if cv2.countNonZero(threshold_img) < img_cropped.size * perc / 100:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def detect_workers(workers, frame):\n",
    "    \"\"\"\n",
    "    Detection of the person with the safety guards.\n",
    "    :param workers: Total number of the person in the current frame\n",
    "    :param frame: Current frame\n",
    "    :return: Total violation count of the person\n",
    "    \"\"\"\n",
    "    violations = 0\n",
    "    global viol_wk\n",
    "    for worker in workers:\n",
    "        xmin, ymin, xmax, ymax = worker\n",
    "        crop = frame[ymin:ymax, xmin:xmax]\n",
    "        if 0 not in crop.shape:\n",
    "            if detect_safety_hat(crop):\n",
    "                if detect_safety_jacket(crop):\n",
    "                    cv2.rectangle(frame, (xmin, ymin), (xmax, ymax),\n",
    "                                  (0, 255, 0), 2)\n",
    "                else:\n",
    "                    cv2.rectangle(frame, (xmin, ymin), (xmax, ymax),\n",
    "                                  (0, 0, 255), 2)\n",
    "                    violations += 1\n",
    "                    viol_wk += 1\n",
    "\n",
    "            else:\n",
    "                cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 0, 255), 2)\n",
    "                violations += 1\n",
    "                viol_wk += 1\n",
    "\n",
    "    return violations\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Load the network and parse the output.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    env_parser()\n",
    "    global is_async_mode\n",
    "    nextReq = 1\n",
    "    currReq = 0\n",
    "    nextReq_s = 1\n",
    "    currReq_s = 0\n",
    "    prevVideo = None\n",
    "    vid_finished = [False] * len(videos)\n",
    "    min_FPS = min([videos[i][1].video.get(cv2.CAP_PROP_FPS) for i in range(len(videos))])\n",
    "    # Initialise the class\n",
    "    infer_network = Network()\n",
    "    infer_network_safety = Network()\n",
    "    # Load the network to IE plugin to get shape of input layer\n",
    "    plugin, (batch_size, channels, model_height, model_width) = \\\n",
    "        infer_network.load_model(conf_modelLayers, targetDevice, 1, 1, 2, cpu_extension)\n",
    "    if use_safety_model:\n",
    "        batch_size_sm, channels_sm, model_height_sm, model_width_sm = \\\n",
    "            infer_network_safety.load_model(conf_safety_modelLayers, targetDevice, 1, 1, 2, cpu_extension, plugin)[1]\n",
    "\n",
    "    while True:\n",
    "        for index, currVideo in videos:\n",
    "            # Read image from video/cam\n",
    "            vfps = int(round(currVideo.video.get(cv2.CAP_PROP_FPS)))\n",
    "            for i in range(0, int(round(vfps / min_FPS))):\n",
    "                ret, current_img = currVideo.video.read()\n",
    "                if not ret:\n",
    "                    vid_finished[index] = True\n",
    "                    break\n",
    "            if vid_finished[index]:\n",
    "                stream_end_frame = np.zeros((int(currVideo.height), int(currVideo.width), 1),\n",
    "                                               dtype='uint8')\n",
    "                cv2.putText(stream_end_frame, \"Input file {} has ended\".format\n",
    "                (name_of_videos[index][1].split('/')[-1]) ,\n",
    "                            (10, int(currVideo.height/2)),\n",
    "                            cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2)\n",
    "                cv2.imshow(currVideo.name, stream_end_frame)\n",
    "                continue\n",
    "            # Transform image to person detection model input\n",
    "            rsImg = cv2.resize(current_img, (model_width, model_height))\n",
    "            rsImg = rsImg.transpose((2, 0, 1))\n",
    "            rsImg = rsImg.reshape((batch_size, channels, model_height, model_width))\n",
    "\n",
    "            infer_start_time = datetime.datetime.now()\n",
    "            # Infer current image\n",
    "            if is_async_mode:\n",
    "                infer_network.exec_net(nextReq, rsImg)\n",
    "            else:\n",
    "                infer_network.exec_net(currReq, rsImg)\n",
    "                prevVideo = currVideo\n",
    "                previous_img = current_img\n",
    "            # Wait for previous request to end\n",
    "            if infer_network.wait(currReq) == 0:\n",
    "                infer_end_time = (datetime.datetime.now() - infer_start_time) * 1000\n",
    "                in_frame_workers = []\n",
    "                people = 0\n",
    "                violations = 0\n",
    "                hard_hat_detection =False\n",
    "                vest_detection = False\n",
    "                result = infer_network.get_output(currReq)\n",
    "                # Filter output\n",
    "                for obj in result[0][0]:\n",
    "                    if obj[2] > conf_inferConfidenceThreshold:\n",
    "                        xmin = int(obj[3] * prevVideo.width)\n",
    "                        ymin = int(obj[4] * prevVideo.height)\n",
    "                        xmax = int(obj[5] * prevVideo.width)\n",
    "                        ymax = int(obj[6] * prevVideo.height)\n",
    "                        xmin = int(xmin - padding) if (xmin - padding) > 0 else 0\n",
    "                        ymin = int(ymin - padding) if (ymin - padding) > 0 else 0\n",
    "                        xmax = int(xmax + padding) if (xmax + padding) <  prevVideo.width else  prevVideo.width\n",
    "                        ymax = int(ymax + padding) if (ymax + padding) <  prevVideo.height else  prevVideo.height\n",
    "                        cv2.rectangle(previous_img, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "                        people += 1\n",
    "                        in_frame_workers.append((xmin, ymin, xmax, ymax))\n",
    "                        new_frame = previous_img[ymin:ymax, xmin:xmax]\n",
    "                        if use_safety_model:\n",
    "                            # Transform image to safety model input\n",
    "                            in_frame_sm = cv2.resize(new_frame, (model_width_sm, model_height_sm))\n",
    "                            in_frame_sm = in_frame_sm.transpose((2, 0, 1))\n",
    "                            in_frame_sm = in_frame_sm.reshape((batch_size_sm, channels_sm, model_height_sm, model_width_sm))\n",
    "\n",
    "                            infer_start_time_sm = datetime.datetime.now()\n",
    "                            if is_async_mode:\n",
    "                                infer_network_safety.exec_net(nextReq_s, in_frame_sm)\n",
    "                            else:\n",
    "                                infer_network_safety.exec_net(currReq_s, in_frame_sm)\n",
    "                            # Wait for the result\n",
    "                            infer_network_safety.wait(currReq_s)\n",
    "                            infer_end_time_sm = (datetime.datetime.now() - infer_start_time_sm) * 1000\n",
    "\n",
    "                            result_sm = infer_network_safety.get_output(currReq_s)\n",
    "                            # Filter output\n",
    "                            hard_hat_detection = False\n",
    "                            vest_detection = False\n",
    "                            detection_list = []\n",
    "                            for obj_sm in result_sm[0][0]:\n",
    "\n",
    "                                if (obj_sm[2] > 0.4):\n",
    "                                    # Detect safety vest\n",
    "                                    if (int(obj_sm[1])) == 2:\n",
    "                                        xmin_sm = int(obj_sm[3] * (xmax-xmin))\n",
    "                                        ymin_sm = int(obj_sm[4] * (ymax-ymin))\n",
    "                                        xmax_sm = int(obj_sm[5] * (xmax-xmin))\n",
    "                                        ymax_sm = int(obj_sm[6] * (ymax-ymin))\n",
    "                                        if vest_detection == False:\n",
    "                                            detection_list.append([xmin_sm+xmin, ymin_sm+ymin, xmax_sm+xmin, ymax_sm+ymin])\n",
    "                                            vest_detection = True\n",
    "\n",
    "                                    # Detect hard-hat\n",
    "                                    if int(obj_sm[1]) == 4:\n",
    "                                        xmin_sm_v = int(obj_sm[3] * (xmax-xmin))\n",
    "                                        ymin_sm_v = int(obj_sm[4] * (ymax-ymin))\n",
    "                                        xmax_sm_v = int(obj_sm[5] * (xmax-xmin))\n",
    "                                        ymax_sm_v = int(obj_sm[6] * (ymax-ymin))\n",
    "                                        if hard_hat_detection == False:\n",
    "                                            detection_list.append([xmin_sm_v+xmin, ymin_sm_v+ymin, xmax_sm_v+xmin, ymax_sm_v+ymin])\n",
    "                                            hard_hat_detection = True\n",
    "\n",
    "                            if hard_hat_detection is False or vest_detection is False:\n",
    "                                violations += 1\n",
    "                            for _rect in detection_list:\n",
    "                                cv2.rectangle(current_img, (_rect[0] , _rect[1]), (_rect[2] , _rect[3]), (0, 255, 0), 2)\n",
    "                            if is_async_mode:\n",
    "                                currReq_s, nextReq_s = nextReq_s, currReq_s\n",
    "\n",
    "                    # Use OpenCV if worker-safety-model is not provided\n",
    "                        else :\n",
    "                            violations = detect_workers(in_frame_workers, previous_img)\n",
    "\n",
    "                # Check if detected violations equals previous frames\n",
    "                if violations == prevVideo.currentViolationCount:\n",
    "                    prevVideo.currentViolationCountConfidence += 1\n",
    "\n",
    "                    # If frame threshold is reached, change validated count\n",
    "                    if prevVideo.currentViolationCountConfidence == conf_inFrameViolationsThreshold:\n",
    "\n",
    "                        # If another violation occurred, save image\n",
    "                        if prevVideo.currentViolationCount > prevVideo.prevViolationCount:\n",
    "                            prevVideo.totalViolations += (prevVideo.currentViolationCount - prevVideo.prevViolationCount)\n",
    "                        prevVideo.prevViolationCount = prevVideo.currentViolationCount\n",
    "                else:\n",
    "                    prevVideo.currentViolationCountConfidence = 0\n",
    "                    prevVideo.currentViolationCount = violations\n",
    "\n",
    "                # Check if detected people count equals previous frames\n",
    "                if people == prevVideo.currentPeopleCount:\n",
    "                    prevVideo.currentPeopleCountConfidence += 1\n",
    "                    # If frame threshold is reached, change validated count\n",
    "                    if prevVideo.currentPeopleCountConfidence == conf_inFrameViolationsThreshold:\n",
    "                        prevVideo.currentTotalPeopleCount += (\n",
    "                                prevVideo.currentPeopleCount - prevVideo.prevPeopleCount)\n",
    "                        if prevVideo.currentTotalPeopleCount > prevVideo.prevPeopleCount:\n",
    "                            prevVideo.totalPeopleCount += prevVideo.currentTotalPeopleCount - prevVideo.prevPeopleCount\n",
    "                        prevVideo.prevPeopleCount = prevVideo.currentPeopleCount\n",
    "                else:\n",
    "                    prevVideo.currentPeopleCountConfidence = 0\n",
    "                    prevVideo.currentPeopleCount = people\n",
    "\n",
    "                frame_end_time = datetime.datetime.now()\n",
    "                cv2.putText(previous_img, 'Total people count: ' + str(\n",
    "                    prevVideo.totalPeopleCount), (10, prevVideo.height - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "                cv2.putText(previous_img, 'Current people count: ' + str(\n",
    "                    prevVideo.currentTotalPeopleCount),\n",
    "                            (10, prevVideo.height - 40),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "                cv2.putText(previous_img, 'Total violation count: ' + str(\n",
    "                    prevVideo.totalViolations), (10, prevVideo.height - 70),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "                cv2.putText(previous_img, 'FPS: %0.2fs' % (1 / (\n",
    "                        frame_end_time - prevVideo.frame_start_time).total_seconds()),\n",
    "                            (10, prevVideo.height - 100),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "                cv2.putText(previous_img, 'Inference time: N\\A for async mode' if is_async_mode else 'Inference time: {}ms'.format((infer_end_time).total_seconds()),\n",
    "                            (10, prevVideo.height - 130),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "                cv2.imshow(prevVideo.name, previous_img)\n",
    "                prevVideo.frame_start_time = datetime.datetime.now()\n",
    "            # Swap\n",
    "            if is_async_mode:\n",
    "                currReq, nextReq = nextReq, currReq\n",
    "                previous_img = current_img\n",
    "                prevVideo = currVideo\n",
    "            # Exit if ESC key is pressed\n",
    "            if cv2.waitKey(1) == 27:\n",
    "                print(\"Attempting to stop input files\")\n",
    "                infer_network.clean()\n",
    "                infer_network_safety.clean()\n",
    "                cv2.destroyAllWindows()\n",
    "                return\n",
    "        \n",
    "        if False not in vid_finished:\n",
    "            infer_network.clean()\n",
    "            infer_network_safety.clean()\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
